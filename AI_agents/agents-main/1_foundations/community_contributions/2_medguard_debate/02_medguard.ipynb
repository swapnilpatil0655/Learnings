{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e42175d",
   "metadata": {},
   "source": [
    "# ğŸ’Š MedGuard Debate\n",
    "AI-driven multi-agent debate system for clinical drug interaction analysis.\n",
    "\n",
    "ğŸ”— Related: See [DrugX](https://drugx.lisekarimi.com) - a production-ready drug interaction platform that queries real medical databases (RxNorm, OpenFDA, DrugBank) to deliver FDA-validated safety assessments without LLM hallucination risks.\n",
    "\n",
    "- ğŸŒ Task: Evaluate medication safety through adversarial multi-perspective debate among specialized medical AI agents\n",
    "- ğŸ§  Model: OpenAI (gpt-4o-mini agents + o3-mini judge)\n",
    "- ğŸ¯ Process: ğŸ‘¤User â†’ ğŸ­3 Agentic Debaters (Cautious/Pragmatic/Patient-Advocate) investigate & argue in parallel â†’ âš–ï¸ Judge LLM synthesizes verdict â†’ ğŸ“‹ Clinical Decision\n",
    "- ğŸ“Œ Output Format: Structured debate with evidence-based arguments from each perspective + judge's balanced clinical recommendation\n",
    "- ğŸ”§ Tools: Mock medical knowledge bases + OpenAI API + asyncio parallel execution\n",
    "- ğŸ§‘â€ğŸ’» Skill Level: Intermediate - needs async Python, agentic design, and multi-agent orchestration\n",
    "\n",
    "ğŸ› ï¸ Requirements\n",
    "- âš™ï¸ Hardware: âœ… CPU is sufficient â€” no GPU required\n",
    "- ğŸ”‘ OpenAI API Key\n",
    "- IPython environment (Jupyter/Colab)\n",
    "\n",
    "---\n",
    "ğŸ“¢ Discover more Agentic AI notebooks on my [GitHub repository](https://github.com/lisekarimi/agentverse) and explore additional AI projects on my [portfolio](https://lisekarimi.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import asyncio\n",
    "import random\n",
    "from typing import List, Dict\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce89cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_AGENT = \"gpt-4o-mini\"\n",
    "MODEL_JUDGE = \"o3-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalKnowledgeBase:\n",
    "    \"\"\"Mock medical research database with biased perspectives\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cautious_evidence(medications: List[str]) -> Dict:\n",
    "        \"\"\"Returns worst-case scenarios and severe warnings\"\"\"\n",
    "        evidence = {\n",
    "            \"case_reports\": [\n",
    "                f\"Case Study #2847: Patient on {medications[0]} experienced severe adverse reaction when {medications[1]} was added\",\n",
    "                f\"Meta-analysis shows {random.randint(15, 40)}% increased risk of complications\"\n",
    "            ],\n",
    "            \"warnings\": [\n",
    "                \"FDA Black Box Warning: Concomitant use may lead to serious outcomes\",\n",
    "                \"Contraindication found in elderly patients (>65 years)\"\n",
    "            ],\n",
    "            \"statistics\": {\n",
    "                \"adverse_events\": random.randint(1200, 5000),\n",
    "                \"severity_score\": random.uniform(7.5, 9.5)\n",
    "            }\n",
    "        }\n",
    "        return evidence\n",
    "\n",
    "    @staticmethod\n",
    "    def get_pragmatic_evidence(medications: List[str]) -> Dict:\n",
    "        \"\"\"Returns balanced clinical practice data\"\"\"\n",
    "        evidence = {\n",
    "            \"clinical_guidelines\": [\n",
    "                f\"ACC/AHA Guidelines: {medications[0]} + {medications[1]} acceptable with monitoring\",\n",
    "                f\"Real-world study: {random.randint(60, 85)}% of patients tolerate combination well\"\n",
    "            ],\n",
    "            \"management_strategies\": [\n",
    "                \"Dose adjustment protocol available for safe co-administration\",\n",
    "                f\"Monitor labs every {random.randint(1, 4)} weeks during concurrent use\"\n",
    "            ],\n",
    "            \"statistics\": {\n",
    "                \"successful_cases\": random.randint(10000, 50000),\n",
    "                \"prescribing_frequency\": f\"{random.randint(20, 45)}% of specialists use this combination\"\n",
    "            }\n",
    "        }\n",
    "        return evidence\n",
    "\n",
    "    @staticmethod\n",
    "    def get_risk_benefit_evidence(medications: List[str], condition: str = \"chronic pain\") -> Dict:\n",
    "        \"\"\"Returns patient-centered outcomes data\"\"\"\n",
    "        evidence = {\n",
    "            \"patient_outcomes\": [\n",
    "                f\"Quality of life improved in {random.randint(65, 85)}% of patients despite interaction risk\",\n",
    "                f\"Alternative therapies showed {random.randint(30, 50)}% lower efficacy\"\n",
    "            ],\n",
    "            \"alternatives\": [\n",
    "                \"Alternative drug X: Less effective but safer profile\",\n",
    "                f\"Non-pharmacological options: Limited success in {condition}\"\n",
    "            ],\n",
    "            \"necessity_factors\": [\n",
    "                f\"Patient condition: {condition} - requires effective management\",\n",
    "                f\"Previous treatment failures: {random.randint(2, 5)} alternatives tried\"\n",
    "            ]\n",
    "        }\n",
    "        return evidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebateAgent:\n",
    "    \"\"\"Agentic LLM that argues from a specific medical perspective\"\"\"\n",
    "\n",
    "    def __init__(self, agent_id: str, perspective: str, stance: str):\n",
    "        self.agent_id = agent_id\n",
    "        self.perspective = perspective  # \"cautious\", \"pragmatic\", \"risk-benefit\"\n",
    "        self.stance = stance\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    async def build_argument(self, medications: List[str], patient_context: str = \"\") -> Dict:\n",
    "        \"\"\"Agent autonomously gathers evidence and builds argument\"\"\"\n",
    "\n",
    "        print(f\"ğŸ¤– {self.agent_id} is investigating...\")\n",
    "\n",
    "        # Agent autonomously selects evidence based on perspective\n",
    "        if self.perspective == \"cautious\":\n",
    "            evidence = MedicalKnowledgeBase.get_cautious_evidence(medications)\n",
    "        elif self.perspective == \"pragmatic\":\n",
    "            evidence = MedicalKnowledgeBase.get_pragmatic_evidence(medications)\n",
    "        else:  # risk-benefit\n",
    "            evidence = MedicalKnowledgeBase.get_risk_benefit_evidence(medications)\n",
    "\n",
    "        # Agent constructs argument using LLM\n",
    "        prompt = self._create_debate_prompt(medications, evidence, patient_context)\n",
    "\n",
    "        try:\n",
    "            argument = await self._call_openai(prompt)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"âŒ LLM API Failed for {self.agent_id}: {str(e)}\")\n",
    "\n",
    "        return {\n",
    "            \"agent\": self.agent_id,\n",
    "            \"perspective\": self.perspective,\n",
    "            \"stance\": self.stance,\n",
    "            \"evidence_gathered\": evidence,\n",
    "            \"argument\": argument\n",
    "        }\n",
    "\n",
    "    def _create_debate_prompt(self, medications: List[str], evidence: Dict, patient_context: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "You are {self.agent_id}, a medical AI agent with a {self.perspective} perspective on drug safety.\n",
    "\n",
    "MEDICATIONS TO ANALYZE: {' + '.join(medications)}\n",
    "PATIENT CONTEXT: {patient_context if patient_context else \"Standard adult patient\"}\n",
    "\n",
    "YOUR STANCE: {self.stance}\n",
    "\n",
    "EVIDENCE YOU'VE GATHERED:\n",
    "{self._format_evidence(evidence)}\n",
    "\n",
    "YOUR TASK:\n",
    "Build a compelling argument for your stance. You are in a debate with other medical agents.\n",
    "\n",
    "1. Present your key concern or recommendation\n",
    "2. Cite the specific evidence you found (reference the studies/data above)\n",
    "3. Address potential counterarguments\n",
    "4. Conclude with a clear clinical recommendation\n",
    "\n",
    "Be persuasive but medically accurate. Use your evidence strategically.\n",
    "Stay in character as a {self.perspective} medical advisor.\n",
    "\n",
    "Format your response as a structured argument with clear reasoning.\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def _format_evidence(self, evidence: Dict) -> str:\n",
    "        \"\"\"Format evidence dict into readable text\"\"\"\n",
    "        formatted = \"\"\n",
    "        for key, value in evidence.items():\n",
    "            formatted += f\"\\n{key.upper().replace('_', ' ')}:\\n\"\n",
    "            if isinstance(value, list):\n",
    "                for item in value:\n",
    "                    formatted += f\"  - {item}\\n\"\n",
    "            elif isinstance(value, dict):\n",
    "                for k, v in value.items():\n",
    "                    formatted += f\"  - {k}: {v}\\n\"\n",
    "            else:\n",
    "                formatted += f\"  - {value}\\n\"\n",
    "        return formatted\n",
    "\n",
    "    async def _call_openai(self, prompt: str) -> str:\n",
    "        response = await asyncio.get_event_loop().run_in_executor(\n",
    "            None,\n",
    "            lambda: self.client.chat.completions.create(\n",
    "                model=MODEL_AGENT,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=400,\n",
    "                temperature=0.7\n",
    "            )\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgeAgent:\n",
    "    \"\"\"Evaluates debate and synthesizes final medical recommendation\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    async def judge_debate(self, arguments: List[Dict], medications: List[str]) -> Dict:\n",
    "        \"\"\"Analyzes all arguments and renders verdict\"\"\"\n",
    "\n",
    "        print(\"âš–ï¸  Judge is deliberating...\")\n",
    "\n",
    "        prompt = self._create_judge_prompt(arguments, medications)\n",
    "\n",
    "        try:\n",
    "            verdict = self._call_openai_judge(prompt)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"âŒ Judge LLM API Failed: {str(e)}\")\n",
    "\n",
    "        return {\n",
    "            \"medications\": medications,\n",
    "            \"arguments_reviewed\": len(arguments),\n",
    "            \"final_verdict\": verdict\n",
    "        }\n",
    "\n",
    "    def _create_judge_prompt(self, arguments: List[Dict], medications: List[str]) -> str:\n",
    "        debate_summary = \"\"\n",
    "        for arg in arguments:\n",
    "            debate_summary += f\"\\n{'='*60}\\n\"\n",
    "            debate_summary += f\"{arg['agent']} ({arg['perspective'].upper()} PERSPECTIVE):\\n\"\n",
    "            debate_summary += f\"Stance: {arg['stance']}\\n\\n\"\n",
    "            debate_summary += f\"{arg['argument']}\\n\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are a senior clinical judge synthesizing a debate about drug interactions.\n",
    "\n",
    "MEDICATIONS: {' + '.join(medications)}\n",
    "\n",
    "DEBATE ARGUMENTS:\n",
    "{debate_summary}\n",
    "\n",
    "YOUR TASK AS JUDGE:\n",
    "1. Evaluate the strength of each argument\n",
    "2. Identify which concerns are most clinically significant\n",
    "3. Note where agents agree and disagree\n",
    "4. Synthesize a balanced, evidence-based final recommendation\n",
    "\n",
    "Your verdict should:\n",
    "- Acknowledge valid points from each perspective\n",
    "- Provide clear clinical guidance\n",
    "- Include specific monitoring/management recommendations\n",
    "- State final risk level: SAFE / CAUTION / WARNING / CONTRAINDICATED\n",
    "\n",
    "Be thorough and fair. This is a clinical decision that affects patient care.\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def _call_openai_judge(self, prompt: str) -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=MODEL_JUDGE,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgenticDebateCoordinator:\n",
    "    \"\"\"Orchestrates the multi-agent debate system\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agents = [\n",
    "            DebateAgent(\n",
    "                \"Dr_Safety_First\",\n",
    "                \"cautious\",\n",
    "                \"These medications should NOT be combined - risks outweigh benefits\"\n",
    "            ),\n",
    "            DebateAgent(\n",
    "                \"Dr_Evidence_Based\",\n",
    "                \"pragmatic\",\n",
    "                \"Combination is acceptable with proper monitoring and management\"\n",
    "            ),\n",
    "            DebateAgent(\n",
    "                \"Dr_Patient_Advocate\",\n",
    "                \"risk-benefit\",\n",
    "                \"Patient needs effective treatment - we must balance safety with quality of life\"\n",
    "            )\n",
    "        ]\n",
    "        self.judge = JudgeAgent()\n",
    "\n",
    "    async def conduct_debate(self, medications: List[str], patient_context: str = \"\") -> Dict:\n",
    "        print(f\"{'='*70}\")\n",
    "        print(\"ğŸ¥ AGENTIC DRUG INTERACTION DEBATE\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"ğŸ“‹ Medications: {' + '.join(medications)}\")\n",
    "        print(f\"ğŸ‘¤ Patient Context: {patient_context if patient_context else 'Standard adult patient'}\")\n",
    "        print(f\"\\nğŸ­ {len(self.agents)} agents are building their arguments...\\n\")\n",
    "\n",
    "        # Each agent autonomously investigates and builds argument\n",
    "        tasks = [agent.build_argument(medications, patient_context) for agent in self.agents]\n",
    "        arguments = await asyncio.gather(*tasks)\n",
    "\n",
    "        print(\"\\nâœ… All arguments prepared. Proceeding to judge...\\n\")\n",
    "\n",
    "        # Judge evaluates the debate\n",
    "        verdict = await self.judge.judge_debate(arguments, medications)\n",
    "\n",
    "        return {\n",
    "            \"medications\": medications,\n",
    "            \"patient_context\": patient_context,\n",
    "            \"arguments\": arguments,\n",
    "            \"verdict\": verdict\n",
    "        }\n",
    "\n",
    "    def display_debate(self, results: Dict):\n",
    "        \"\"\"Format and display the debate results\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"ğŸ“Š DEBATE RESULTS\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "\n",
    "        # Display each agent's argument\n",
    "        for i, arg in enumerate(results['arguments'], 1):\n",
    "            print(f\"{'â”€'*70}\")\n",
    "            print(f\"ğŸ¤ ARGUMENT #{i}: {arg['agent']}\")\n",
    "            print(f\"{'â”€'*70}\")\n",
    "            print(f\"ğŸ“Œ Perspective: {arg['perspective'].upper()}\")\n",
    "            print(f\"ğŸ¯ Stance: {arg['stance']}\")\n",
    "            print(\"\\nğŸ’¬ ARGUMENT:\")\n",
    "            print(f\"{arg['argument']}\")\n",
    "            print()\n",
    "\n",
    "        # Display judge's verdict\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"âš–ï¸  JUDGE'S FINAL VERDICT\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"{results['verdict']['final_verdict']}\")\n",
    "        print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    coordinator = AgenticDebateCoordinator()\n",
    "\n",
    "    # Test case 1: Classic dangerous interaction\n",
    "    print(\"ğŸš€ Starting Agentic Debate System...\\n\")\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"medications\": [\"Warfarin\", \"Ibuprofen\"],\n",
    "            \"context\": \"72-year-old patient with atrial fibrillation and severe osteoarthritis\"\n",
    "        },\n",
    "        # Uncomment to test more scenarios:\n",
    "        # {\n",
    "        #     \"medications\": [\"Metformin\", \"Alcohol\"],\n",
    "        #     \"context\": \"45-year-old diabetic patient, social drinker\"\n",
    "        # },\n",
    "        # {\n",
    "        #     \"medications\": [\"SSRI Antidepressant\", \"Tramadol\"],\n",
    "        #     \"context\": \"Patient with depression and chronic back pain\"\n",
    "        # }\n",
    "    ]\n",
    "\n",
    "    for test in test_cases:\n",
    "        results = await coordinator.conduct_debate(\n",
    "            test[\"medications\"],\n",
    "            test[\"context\"]\n",
    "        )\n",
    "        coordinator.display_debate(results)\n",
    "        await asyncio.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd32e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the debate system\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
